hashing  
    que es  
    Es una técnica para almacenar datos de forma eficiente, usando una función hash para convertir una clave (key) en una posición de almacenamiento (índice en un array).  
    Ideal para búsquedas rápidas, con tiempo promedio O(1).  
    Puede haber colisiones: dos claves distintas que generan el mismo índice.  
    Para resolver colisiones se usan métodos como:  
        Open hashing (encadenamiento)  
        Closed hashing (sondeo lineal, cuadrático, doble hash)  
    Búsqueda, inserción y eliminación:  
        Promedio: O(1)  
        Peor caso (todas las claves colisionan): O(n)

    para que se usa  
    Para implementar tablas hash o diccionarios.  
    En estructuras como sets, maps, caches, y bases de datos.  
    En verificación de datos (checksums, firmas).  
    Para almacenar y buscar elementos de forma rápida (como en compiladores, sistemas de archivos, etc.).

open hashing  
    que hace  
    Cada posición del array (hash table) contiene una lista enlazada (o estructura similar).  
    Si varias claves caen en la misma posición (colisión), se encadenan en esa lista.  
    No se necesita buscar una nueva posición para insertar, solo agregar al final de la lista.  
    inserción, búsqueda, eliminación:  
        Promedio: O(1 + α)  
        (donde α = n/m es el factor de carga: cantidad de elementos / cantidad de posiciones)  
        Peor caso: O(n) si todos caen en la misma lista  

    para que se usa  
    Cuando se quiere evitar la complejidad del sondeo y trabajar con estructuras dinámicas.  
    Es más flexible en caso de muchas colisiones.  
    Útil cuando no hay límite fijo de elementos (listas pueden crecer).  

dijkstra  
    orden  
    O(V^2) sin heap / O((V+E) log V) con heap  

    que hace  
    Encuentra el camino más corto desde un nodo origen a todos los demás nodos de un grafo.  
    Funciona solo con pesos no negativos.  
    Utiliza una estructura de datos tipo cola de prioridad (como un heap o priority queue).  
    Es un algoritmo greedy (avanza eligiendo la opción óptima local).  
    Guarda las distancias mínimas conocidas desde el nodo origen y las va actualizando si encuentra un camino más corto.  

    sirve para  
    Calcular rutas más cortas en mapas, redes o grafos (como Google Maps).  
    En redes de computadoras: enrutamiento de paquetes (como en protocolos OSPF).  
    En videojuegos: movimiento de personajes o enemigos hacia un objetivo.  
    Planificación de rutas, logística, sistemas de transporte, etc.  

floyd  
    que hace  
    Calcula todas las distancias mínimas entre todos los pares de nodos en un grafo.  
    Sirve para grafos con pesos negativos, pero sin ciclos negativos.  
    Es un algoritmo de programación dinámica.  
    Utiliza una matriz de distancias, que se va actualizando en cada paso.  
    Se basa en la idea de ir considerando todos los vértices como posibles intermediarios en los caminos.  
    orden de ejecución: O(V³)

    sirve para  
    Cuando se necesita saber la distancia mínima entre todos los pares de nodos, no solo desde uno.  
    En análisis de redes, como determinar el nodo más central o el camino más eficiente entre cualquiera de dos puntos.  
    En grafos densos (muchas conexiones), o cuando no se necesita alta eficiencia en tiempo.  
    En planificación de rutas, tráfico, logística, análisis de caminos entre ciudades, etc.

busqueda en profundidad (DFS)  
    que hace  
    Explora un grafo o árbol profundamente, yendo por un camino hasta que no puede avanzar más, y luego retrocede (backtracking).  
    Utiliza una pila (stack) para llevar el control de los nodos a visitar.  
        En implementación recursiva, la pila es la pila del sistema.  
    Puede aplicarse a grafos dirigidos o no dirigidos, y a árboles.  
    Puede detectar ciclos, componentes conexas, y sirve para recorridos topológicos.  
    Es no óptimo para encontrar el camino más corto, pero visita todos los nodos alcanzables.  

    detalles importantes  
    Complejidad: O(V + E)  
    Avance: visitar un nodo no visitado.  
    Retroceso: volver atrás cuando no hay más vecinos no visitados.  
    También puede clasificar aristas en avance, retroceso o cruzadas.  

    para que sirve  
    Recorrer grafos o árboles.  
    Encontrar componentes conexas.  
    Detectar ciclos en grafos dirigidos o no dirigidos.  
    Resolver laberintos.  
    Hacer ordenamiento topológico en grafos dirigidos acíclicos.  
    Resolver problemas de backtracking (sudoku, rompecabezas, etc.).

busqueda en anchura (BFS)  
    que hace  
    Explora un grafo nivel por nivel: primero los vecinos del nodo inicial, luego los vecinos de esos vecinos, etc.  
    Usa una cola (queue) para mantener el orden de visita.  
    Encuentra el camino más corto en cantidad de aristas en grafos no ponderados.  
    Visita todos los nodos alcanzables desde el nodo origen.  

    detalles importantes  
    Complejidad: O(V + E)  
    Se exploran primero los nodos a distancia 1, luego a distancia 2, etc.  
    Construye un árbol de expansión desde el nodo origen.  

    para que sirve  
    Encontrar caminos mínimos en grafos no ponderados.  
    Verificar si un grafo es conexo.  
    Calcular distancias mínimas.  
    Resolver problemas como:  
        Nivel mínimo en un laberinto.  
        Menor cantidad de movimientos.  
        Redes de comunicación o rutas más cortas en mapas.

kruskal  
    que hace  
    Encuentra el árbol generador mínimo (MST) en un grafo ponderado.  
    Ordena las aristas por peso y las va agregando sin formar ciclos.  
    Usa estructura de conjuntos disjuntos (union-find).  
    Es un algoritmo greedy.  

    orden  
    O(m log m), donde m es la cantidad de aristas  

    para que sirve  
    Construcción de redes de costo mínimo.  
    Conexiones más económicas.  
    Planificación de rutas.  
    Agrupamiento jerárquico (clustering).  
    Mejor en grafos dispersos.  

prim  
    que hace  
    También busca el árbol generador mínimo.  
    Empieza en un nodo cualquiera y va expandiendo el árbol agregando la arista más barata hacia un nodo no visitado.  
    Usa una cola de prioridad.  
    Es greedy, como Kruskal.  

    orden  
    O(m log n), donde m es la cantidad de aristas y n de vértices  

    para que sirve  
    Planificación de redes desde un nodo inicial.  
    Instalación de fibra óptica desde un punto.  
    Útil en grafos densos.  
    Aplicaciones similares a Kruskal, pero diferente estrategia.


inserción directa  
    que hace  
    Ordena un arreglo comparando cada elemento con los anteriores e insertándolo en la posición correcta.  
    Es eficiente si el arreglo ya está parcialmente ordenado.  
    Es un algoritmo in-place (no usa memoria adicional significativa).  
    Similar a ordenar cartas en la mano: cada nueva carta se inserta donde corresponde.  

    complejidad  
        Mejor caso (ya ordenado): O(n)  
        Promedio y peor caso: O(n²)  

    para que sirve  
    Ordenar pequeños conjuntos de datos.  
    Casos donde los datos ya están casi ordenados.  
    Como parte de algoritmos híbridos (ej. Timsort). 


shellsort
    que hace
    Ordena un arreglo utilizando una secuencia de incrementos (gaps) que permite comparar y mover elementos que están lejos entre sí.
    Es una mejora del algoritmo de inserción directa, optimizando el número de movimientos.
    Reduce el salto progresivamente hasta llegar a 1, donde termina como una inserción directa.

    orden
    Depende de la secuencia de gaps usada.
    En general, mejor que O(n²); por ejemplo, con la secuencia de Hibbard o Sedgewick se logra
    un orden cercano a O(n log² n) o incluso O(n^3/2).

    para que sirve
    Ordenamiento eficiente para arreglos medianos.
    Útil cuando no se quiere usar estructuras adicionales (es in-place).
    Ideal en sistemas con poca memoria.
    A veces se utiliza como parte de otros algoritmos o en ordenamientos híbridos.